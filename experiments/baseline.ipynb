{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3defc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listening_counts = pd.read_csv('listening-counts.tsv', sep='\\t')\n",
    "users = pd.read_csv('users.tsv', sep='\\t')\n",
    "users_sample = users.sample(2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acedb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_sample = listening_counts[listening_counts['user_id'].isin(users_sample['user_id'])]\n",
    "counts_sample['rating'] = counts_sample['count'] / counts_sample.groupby('user_id')['count'].transform('max')\n",
    "ratings_df = counts_sample[counts_sample['track_id'].isin(\\\n",
    "            list(counts_sample.groupby('track_id').sum()['rating'].sort_values(ascending=False)[:3000].index))]\n",
    "ratings_df['tracks_count'] = ratings_df.groupby('user_id')['count'].transform('count')\n",
    "ratings_df = ratings_df[ratings_df['tracks_count'] >= 5]\n",
    "ratings_df.drop(columns=['count', 'tracks_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f839c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions on Train set: 334009\n",
      "Actions on Test set: 83503\n"
     ]
    }
   ],
   "source": [
    "ratings_df_train, ratings_df_test = train_test_split(ratings_df,\n",
    "                                   stratify=ratings_df['user_id'],\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('Actions on Train set: %d' % len(ratings_df_train))\n",
    "print('Actions on Test set: %d' % len(ratings_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f2642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.set_index('user_id')\n",
    "ratings_df_train = ratings_df_train.set_index('user_id')\n",
    "ratings_df_test = ratings_df_test.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5b239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_listened(person_id, listened_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    listened_items = listened_df.loc[person_id]['track_id']\n",
    "    return set(listened_items if type(listened_items) == pd.Series else [listened_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94fbd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = set(ratings_df['track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f5b00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_listened_items_sample(self, person_id, sample_size, seed=42):\n",
    "        listened_items = get_items_listened(person_id, ratings_df)\n",
    "        non_listened_items = all_items - listened_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_listened_items_sample = random.sample(non_listened_items, sample_size)\n",
    "        return set(non_listened_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        listened_values_testset = ratings_df_test.loc[person_id]\n",
    "        if type(listened_values_testset['track_id']) == pd.Series:\n",
    "            person_listened_items_testset = set(listened_values_testset['track_id'])\n",
    "        else:\n",
    "            person_listened_items_testset = set([int(listened_values_testset['track_id'])])\n",
    "        listened_items_count_testset = len(person_listened_items_testset)\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id,\n",
    "                                               items_to_ignore=get_items_listened(person_id,\n",
    "                                                                                    ratings_df_train),\n",
    "                                               topn=100000000)\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has listened in test set\n",
    "        for item_id in person_listened_items_testset:\n",
    "            # Getting a random sample (100) items the user has not listened \n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_listened_items_sample = self.get_not_listened_items_sample(person_id,\n",
    "                                                                               sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS,\n",
    "                                                                               seed=item_id % (2 ** 32))\n",
    "\n",
    "            # Combining the current listened item with the 100 random items\n",
    "            items_to_filter_recs = non_listened_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the listened item or from a random sample of 100 non-listened items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['track_id'].isin(items_to_filter_recs)]\n",
    "            valid_recs = valid_recs_df['track_id'].values\n",
    "            # Verifying if the current listened item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "        # Recall is the rate of the listened items that are ranked among the Top-N recommended items, \n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(listened_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(listened_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count': hits_at_5_count,\n",
    "                          'hits@10_count': hits_at_10_count,\n",
    "                          'listened_count': listened_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        # print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(tqdm(list(ratings_df_test.index.unique().values))):\n",
    "            # if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
    "            person_metrics['user_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "            .sort_values('listened_count', ascending=False)\n",
    "\n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(\n",
    "            detailed_results_df['listened_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(\n",
    "            detailed_results_df['listened_count'].sum())\n",
    "\n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}\n",
    "        return global_metrics, detailed_results_df\n",
    "\n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853db410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3b2bdb4b23488898743325d194bc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1855 users processed\n"
     ]
    }
   ],
   "source": [
    "class Baseline:\n",
    "    MODEL_NAME = 'Baseline (Const Popularity)'\n",
    "    \n",
    "    def __init__(self, popularity_df):\n",
    "        self.popularity_df = popularity_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        # Рекомендуем самые популярные треки, которые еще не слушал пользователь\n",
    "        temp_df = ratings_df.groupby('track_id')['rating'].sum().sort_values(ascending=False)\\\n",
    "                                        .reset_index().rename(columns={'rating': 'rateStrength'})\n",
    "        recommendations_df = temp_df[~temp_df['track_id'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('rateStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "        return recommendations_df\n",
    "\n",
    "Baseline_model = Baseline(ratings_df_train)\n",
    "base_global_metrics, base_detailed_results_df = model_evaluator.evaluate_model(Baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f847c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Baseline (Const Popularity)', 'recall@5': 0.12110942121839934, 'recall@10': 0.20401662215728777}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>listened_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>56</td>\n",
       "      <td>90</td>\n",
       "      <td>371</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.242588</td>\n",
       "      <td>48315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>358</td>\n",
       "      <td>0.114525</td>\n",
       "      <td>0.254190</td>\n",
       "      <td>6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>86</td>\n",
       "      <td>117</td>\n",
       "      <td>358</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.326816</td>\n",
       "      <td>24770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>353</td>\n",
       "      <td>0.110482</td>\n",
       "      <td>0.172805</td>\n",
       "      <td>3556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>333</td>\n",
       "      <td>0.084084</td>\n",
       "      <td>0.186186</td>\n",
       "      <td>28467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>63</td>\n",
       "      <td>309</td>\n",
       "      <td>0.122977</td>\n",
       "      <td>0.203883</td>\n",
       "      <td>41663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45</td>\n",
       "      <td>71</td>\n",
       "      <td>294</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.241497</td>\n",
       "      <td>47286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>49</td>\n",
       "      <td>75</td>\n",
       "      <td>293</td>\n",
       "      <td>0.167235</td>\n",
       "      <td>0.255973</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>292</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>73816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>49</td>\n",
       "      <td>71</td>\n",
       "      <td>288</td>\n",
       "      <td>0.170139</td>\n",
       "      <td>0.246528</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hits@5_count  hits@10_count  listened_count  recall@5  recall@10  user_id\n",
       "104            56             90             371  0.150943   0.242588    48315\n",
       "661            41             91             358  0.114525   0.254190     6110\n",
       "192            86            117             358  0.240223   0.326816    24770\n",
       "29             39             61             353  0.110482   0.172805     3556\n",
       "3              28             62             333  0.084084   0.186186    28467\n",
       "2              38             63             309  0.122977   0.203883    41663\n",
       "23             45             71             294  0.153061   0.241497    47286\n",
       "105            49             75             293  0.167235   0.255973     8760\n",
       "313            66             96             292  0.226027   0.328767    73816\n",
       "34             49             71             288  0.170139   0.246528     1592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % base_global_metrics)\n",
    "base_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c01df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, cf_predictions_df, number_of_factors=15):\n",
    "        self.cf_predictions_df = cf_predictions_df\n",
    "        self.number_of_factors = number_of_factors\n",
    "        self._prep_data()\n",
    "\n",
    "    def _prep_data(self):\n",
    "        pivot_train = self.cf_predictions_df.pivot_table(index='user_id', columns='track_id', values='rating').fillna(0)\n",
    "        csr_coll_matrix_train = csr_matrix(pivot_train)\n",
    "        U, sigma, Vt = svds(csr_coll_matrix_train, k = self.number_of_factors)\n",
    "        sigma = np.diag(sigma)\n",
    "        predicted_ratings_train = np.dot(np.dot(U, sigma), Vt) \n",
    "        predicted_ratings_train_norm = (predicted_ratings_train - \n",
    "                                        predicted_ratings_train.min()) / (predicted_ratings_train.max()\n",
    "                                                                        - predicted_ratings_train.min())\n",
    "        self.cf_predictions_df = pd.DataFrame(predicted_ratings_train_norm,\n",
    "                           columns = pivot_train.columns,\n",
    "                           index=list(pivot_train.index)).transpose()\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10):\n",
    "        # Get and sort the user's predictions\n",
    "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
    "                                    .reset_index().rename(columns={user_id: 'recStrength'})\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['track_id'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('recStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        return recommendations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce72b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_recommender_model = CFRecommender(ratings_df_train, number_of_factors=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c40ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d04fbd11e6d4dbd9ba3657c571bfb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1855 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'recall@5': 0.33491012298959316, 'recall@10': 0.4600912542064357}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>listened_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>90</td>\n",
       "      <td>126</td>\n",
       "      <td>371</td>\n",
       "      <td>0.242588</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>48315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>136</td>\n",
       "      <td>161</td>\n",
       "      <td>358</td>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.449721</td>\n",
       "      <td>6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>106</td>\n",
       "      <td>153</td>\n",
       "      <td>358</td>\n",
       "      <td>0.296089</td>\n",
       "      <td>0.427374</td>\n",
       "      <td>24770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>91</td>\n",
       "      <td>125</td>\n",
       "      <td>353</td>\n",
       "      <td>0.257790</td>\n",
       "      <td>0.354108</td>\n",
       "      <td>3556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>106</td>\n",
       "      <td>333</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>0.318318</td>\n",
       "      <td>28467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>309</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.304207</td>\n",
       "      <td>41663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>106</td>\n",
       "      <td>141</td>\n",
       "      <td>294</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>47286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>293</td>\n",
       "      <td>0.208191</td>\n",
       "      <td>0.310580</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>105</td>\n",
       "      <td>129</td>\n",
       "      <td>292</td>\n",
       "      <td>0.359589</td>\n",
       "      <td>0.441781</td>\n",
       "      <td>73816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>288</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hits@5_count  hits@10_count  listened_count  recall@5  recall@10  user_id\n",
       "104            90            126             371  0.242588   0.339623    48315\n",
       "661           136            161             358  0.379888   0.449721     6110\n",
       "192           106            153             358  0.296089   0.427374    24770\n",
       "29             91            125             353  0.257790   0.354108     3556\n",
       "3              75            106             333  0.225225   0.318318    28467\n",
       "2              66             94             309  0.213592   0.304207    41663\n",
       "23            106            141             294  0.360544   0.479592    47286\n",
       "105            61             91             293  0.208191   0.310580     8760\n",
       "313           105            129             292  0.359589   0.441781    73816\n",
       "34             72            104             288  0.250000   0.361111     1592"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluator = ModelEvaluator()\n",
    "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
    "cf_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa410d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf70c2be34cefc8925ac37ac24c67051bedf097ccd73ad491733282b57292c88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
